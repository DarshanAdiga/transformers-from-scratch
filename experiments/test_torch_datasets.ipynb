{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook to download and use PyTorch text datasets\n",
    "In this notebook, [YelpReviewPolarity](https://pytorch.org/text/stable/datasets.html#torchtext.datasets.YelpReviewPolarity) is used.\n",
    "\n",
    "**References:**\n",
    "- https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import YelpReviewPolarity\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data_tmp'\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "t_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torchtext.data.datasets_utils._RawTextIterableDataset at 0x7f9d107c14f0>,\n",
       " <torchtext.data.datasets_utils._RawTextIterableDataset at 0x7f9d91092f10>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARN: If  you get an error regarding confirm_token, restart the notebook and run again\n",
    "train_dataset_iter, test_dataset_iter = YelpReviewPolarity(DATA_DIR)\n",
    "(train_dataset_iter, test_dataset_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configurations\n",
    "Get the dataset configurations necessary for building the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Out-of-vocabulary words (<unk>) is:0\n"
     ]
    }
   ],
   "source": [
    "# First, create a tokenizer and vocabulary for the given dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"subword\")\n",
    "\n",
    "def yield_tokenizer(data_iterator):\n",
    "    # We don't need the label_id here\n",
    "    for label_id, text in data_iterator:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create a vocabulary from the training corpus\n",
    "# Note: these iterators are one-off and cannot be reused \n",
    "train_dataset_iter = YelpReviewPolarity(DATA_DIR, split='train')\n",
    "vocabulary = build_vocab_from_iterator(yield_tokenizer(train_dataset_iter), specials=[\"<unk>\"])\n",
    "vocabulary.set_default_index(vocabulary[\"<unk>\"])\n",
    "oov_index = vocabulary.get_default_index()\n",
    "print(f\"Index of Out-of-vocabulary words (<unk>) is:{oov_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, we define various data processing steps as a pipeline\n",
    "# Convert text to sequence of numbers\n",
    "text_pipeline = lambda text: vocabulary(tokenizer(text))\n",
    "# Labels are [1, 2], convert them into [0, 1]\n",
    "label_pipeline = lambda label: int(label) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_using_collate_batch(batch):\n",
    "    \"\"\"Given a batch of samples generated by DataLoader. This collate function uses the data processing \\\n",
    "        pipelines defined earlier.\n",
    "\n",
    "        All the text samples within a batch are merged into one 1-D tensor object. In order to recognize \\\n",
    "            where one text sample ends and where the next starts, we use an array of indices called 'offests'.\n",
    "\n",
    "        Offsets indicate the starting index of each of the samples within the bulk text tensor object.\n",
    "\n",
    "    Args:\n",
    "        batch (iterator): A batch of (label, text) samples\n",
    "\n",
    "    Returns:\n",
    "        tuple: (batch_label_tensor, batch_token_id_tensor, batch_offset_tensor)\n",
    "    \"\"\"\n",
    "    label_list, text_tensor_list, offsets = [], [], [0]\n",
    "\n",
    "    # Process and accumulate the samples within this batch\n",
    "    for label, text in batch:\n",
    "        # Preprocess & Accumulate the labels\n",
    "        label = label_pipeline(label)\n",
    "        label_list.append(label)\n",
    "\n",
    "        #  Preprocess & Accumulate the texts\n",
    "        text_token_ids = text_pipeline(text)\n",
    "        text_tensor = torch.tensor(text_token_ids, dtype=torch.int64)\n",
    "        text_tensor_list.append(text_tensor) # A list of tensors\n",
    "\n",
    "        # TODO: Shouldn't I do padding and truncation here??\n",
    "\n",
    "        # Keep track of the offsets: the starting positions of each sequence of token ids\n",
    "        offsets.append(text_tensor.size()[0]) #Note this is same as tensor.size(dim=0)  \n",
    "    \n",
    "    # Aggregate the sample tensors into 3 individual bulk tensors; \n",
    "    # Bulk tensor for offset\n",
    "    batch_offset_tensor = torch.tensor(offsets[:-1])\n",
    "    batch_offset_tensor = batch_offset_tensor.cumsum(dim=0)\n",
    "    # Note above, cumulative sum produces something like [0, 15, 40, 68, ...],\n",
    "    # indicating the starting positions of every sequence-of-token-ids in the bulk token tensor\n",
    "\n",
    "    # Bulk tensor for label\n",
    "    batch_label_tensor = torch.tensor(label_list, dtype=torch.int64)\n",
    "\n",
    "    # Bulk tensor for text; concatenate a list of tensor objects into a single tensor object\n",
    "    batch_token_id_tensor = torch.cat(text_tensor_list)\n",
    "\n",
    "    # Each of these tensor objects are 1-D tensors; label & offset tensors will be same size as batch, \\\n",
    "    #   the size of token-id tensor will vary among batch to batch\n",
    "    return batch_label_tensor, batch_token_id_tensor, batch_offset_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [Only for Test] Create the one-off iterators and then the dataloaders\n",
    "# from torch.utils.data import DataLoader\n",
    "# train_dataset_iter, test_dataset_iter = YelpReviewPolarity(DATA_DIR)\n",
    "# train_dataloader = DataLoader(train_dataset_iter, batch_size=8, shuffle=False, collate_fn=preprocess_data_using_collate_batch)\n",
    "# test_dataloader = DataLoader(test_dataset_iter, batch_size=8, shuffle=False, collate_fn=preprocess_data_using_collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE EPOCHS EMB_SIZE VOCAB_SIZE CLASSES\n",
      "16 \t 10 \t 512 \t 293202 {1, 2}\n"
     ]
    }
   ],
   "source": [
    "# The configurations\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "EMB_SIZE = 512\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "# Note: these iterators are one-off and cannot be reused \n",
    "train_dataset_iter = YelpReviewPolarity(DATA_DIR, split='train')\n",
    "CLASSES = set([label for label,_ in train_dataset_iter])\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print('BATCH_SIZE', 'EPOCHS', 'EMB_SIZE', 'VOCAB_SIZE', 'CLASSES')\n",
    "print(BATCH_SIZE, '\\t', EPOCHS, '\\t', EMB_SIZE, '\\t', VOCAB_SIZE, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to train and test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "def train_one_epoch(model, train_dataloader, optimizer, criterion, clip_norm, cur_epoch, log_interval=500):\n",
    "    \"\"\"Train the 'model' on one epoch on the 'train_dataloader'.\n",
    "    Returns the model object back.\n",
    "    \"\"\"\n",
    "    model.train() # Train mode\n",
    "    train_size = len(train_dataloader)\n",
    "    cur_true_count, cur_sample_count = 0,0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for iteration, (batch_labels, batch_token_seq, batch_offset) in enumerate(train_dataloader):\n",
    "        # Reset grads\n",
    "        optimizer.zero_grad()\n",
    "        # Predict\n",
    "        batch_prediction = model(batch_token_seq, batch_offset)\n",
    "        # Compute loss\n",
    "        loss = criterion(batch_prediction, batch_labels)\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Clip the gradients; to prevent exploding gradients\n",
    "        clip_grad_norm_(model.parameters(), max_norm=clip_norm)\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute the accuracy metrics\n",
    "        pred_labels = batch_prediction.argmax(dim=1)\n",
    "        true_count = (pred_labels == batch_labels).sum().item()\n",
    "        cur_true_count += true_count\n",
    "        cur_sample_count += batch_labels.size(dim=0) # Same as doing .size()[0]\n",
    "        cur_accuracy = cur_true_count/cur_sample_count\n",
    "\n",
    "        # Log the metrics\n",
    "        if iteration % log_interval == 0 and iteration > 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Epoch: {cur_epoch:3d} \\t Batches: {iteration:5d}/{train_size:5d} \\t \\\n",
    "                Time: {elapsed_time:5.2f}s \\t Accuracy: {cur_accuracy:8.3f}\")\n",
    "\n",
    "            # reset the metrics\n",
    "            cur_true_count, cur_sample_count = 0,0\n",
    "            start_time = time.time()\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_dataloader):\n",
    "    \"\"\"Evaluate the model on eval_dataloader and return the accuracy\n",
    "    \"\"\"\n",
    "    final_true_count, final_sample_count = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_labels, batch_token_seq, batch_offset) in eval_dataloader:\n",
    "            batch_prediction = model(batch_token_seq, batch_offset)\n",
    "            pred_labels = batch_prediction.argmax(dim=1)\n",
    "            true_count = (pred_labels == batch_labels).sum().item()\n",
    "\n",
    "            final_true_count += true_count\n",
    "            final_sample_count += batch_labels.size(dim=0)\n",
    "\n",
    "        # Compute & return the accuracy\n",
    "        return (final_true_count/final_sample_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare train & validation splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Create the one-off iterators and then the dataloaders\n",
    "train_dataset_iter, test_dataset_iter = YelpReviewPolarity(DATA_DIR)\n",
    "# Convert iterable-type datasets into map-type datasets\n",
    "train_dataset = to_map_style_dataset(train_dataset_iter)\n",
    "test_dataset = to_map_style_dataset(test_dataset_iter)\n",
    "\n",
    "# Split 95% and 5% for train & validation sets\n",
    "total_train_size = len(train_dataset)\n",
    "train_size = int(total_train_size * 0.95)\n",
    "train_split, val_split = random_split(train_dataset, [train_size, total_train_size-train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders for train and test datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the dataloaders\n",
    "train_dataloader = DataLoader(train_split, batch_size=BATCH_SIZE, shuffle=True, collate_fn=preprocess_data_using_collate_batch)\n",
    "val_dataloader = DataLoader(val_split, batch_size=BATCH_SIZE, shuffle=False, collate_fn=preprocess_data_using_collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=preprocess_data_using_collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (token_embedding_layer): Embedding(293202, 512)\n",
       "  (position_embedding_layer): Embedding(512, 512)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multihead_attention): MultiHeadSelfAttention(\n",
       "        (layer_weight_keys): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_queries): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_values): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_merge_attention_heads): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multihead_attention): MultiHeadSelfAttention(\n",
       "        (layer_weight_keys): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_queries): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_values): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_merge_attention_heads): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (multihead_attention): MultiHeadSelfAttention(\n",
       "        (layer_weight_keys): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_queries): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_values): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_merge_attention_heads): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (multihead_attention): MultiHeadSelfAttention(\n",
       "        (layer_weight_keys): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_queries): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_values): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_merge_attention_heads): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (multihead_attention): MultiHeadSelfAttention(\n",
       "        (layer_weight_keys): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_queries): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_values): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_merge_attention_heads): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (multihead_attention): MultiHeadSelfAttention(\n",
       "        (layer_weight_keys): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_queries): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_weight_values): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        (layer_merge_attention_heads): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (output_linear_layer): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model class\n",
    "import sys\n",
    "sys.path.insert(0, '../mini-self-attention/')\n",
    "from transformer_classifier import TransformerClassifier\n",
    "\n",
    "classifier_model = TransformerClassifier(emb_size=EMB_SIZE, heads=8, num_of_blocks=6, seq_len=512, \\\n",
    "    vocab_size=VOCAB_SIZE, num_classes=NUM_CLASSES)\n",
    "\n",
    "classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE=0.1\n",
    "lr_warmup_step=5\n",
    "gradient_clip = 1.0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classifier_model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_warmup_step, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92804/468508724.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Train one full epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_92804/187281353.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, optimizer, criterion, clip_norm, cur_epoch, log_interval)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mbatch_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_token_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LAB_VENV/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# The Training Process\n",
    "total_accuracy = None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    epoch_start_time = time.time()\n",
    "    # Train one full epoch\n",
    "    train_one_epoch(classifier_model, train_dataloader, optimizer, criterion, gradient_clip, epoch)\n",
    "\n",
    "    # Evaluate\n",
    "    val_accuracy = evaluate(classifier_model, val_dataloader)\n",
    "    if total_accuracy is not None and total_accuracy > val_accuracy:\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "    else:\n",
    "        # Consider the current accuracy as best accuracy\n",
    "        total_accuracy = val_accuracy\n",
    "    \n",
    "    # Print the metrics at the end of every epoch\n",
    "    print('-' * 60)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print(f\"End of epoch:{epoch:3d} \\t Time taken:{time_taken:5.2f}s \\t Val Acc:{val_accuracy:8.3f}\")\n",
    "    print('-' * 60)\n",
    "\n",
    "print(\"End of training process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Performance on the Test data\")\n",
    "test_accuracy = evaluate(test_dataloader)\n",
    "print(f\"Test Accuracy:{test_accuracy:8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "224e3b60dcce273f5f7665f5803a94c2258e151dae11dd21b290a6633eac9c6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('LAB_VENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
